# -*- coding: utf-8 -*-
"""AI_PDF_HANDWRITTEN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCZUs74AHvwA7vCf_pTPQ7-CUhg8Hq-g
"""

# Install system-level dependencies
!apt-get install -y poppler-utils tesseract-ocr

# Install Python power-tools
!pip install pytesseract pdf2image transformers torch
!pip install transformers==4.35.2

import re
import os
import pytesseract
from pdf2image import convert_from_path
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline

class HandwrittenNoteArchitect:
    def __init__(self):
        print("üöÄ Initializing FAST AI Summarizer (DistilBART)...")
        # device=-1 uses CPU. If you enable GPU in Colab, change to device=0
        self.summarizer = pipeline(
        "text2text-generation",
        model="sshleifer/distilbart-cnn-12-6",
        device=-1
        )
        self.headings = []
        self.final_output = ""

    def clean_text(self, text):
        # 1. Remove Page Artifacts (Dynamic Pattern: Word + Number + Random junk)
        # This catches "CHAPTER 12", "PAGE 5", "REPRINT 2025" without naming them
        text = re.sub(r'(?i)(CHAPTER|PAGE|REPRINT|UNIT)\s+[A-Z0-9]+', '', text)

        # 2. Fix OCR "Stutter"
        # (Removes single letters hanging at the start of lines, common in OCR)
        text = re.sub(r'\n[a-zA-Z]\s\n', '\n', text)

        # 3. Standard Character Clean
        text = re.sub(r'[^A-Za-z0-9\s\.,!\?\-]', '', text)

        # --- NEW: Roman List & Noise Eraser ---
        # Catches 'iii the', 'iv the', 'ii the' etc. to prevent heading triggers
        # Handles 1 to 4 Roman characters (i to viii coverage)
        text = re.sub(r'\b[ivx]{1,4}\s+the\b', '', text, flags=re.IGNORECASE)

        # NEW: The "Junk I" Eraser
        # Removes 'I' only if it's a standalone character in the middle of a sentence
        text = re.sub(r'\b[I]\b', '', text)

        # 4. The "Whitespace Glue"
        # OCR often puts random newlines in the middle of a sentence.
        # This joins them so the AI sees a continuous thought.
        text = " ".join(text.split())

        return text

    def summarize_block(self, text_block):
        """Prevents IndexError by splitting large text into 400-word bites"""
        words = text_block.split()
        chunk_size = 600  #HERE ITS 400
        summarized_chunks = []

        for i in range(0, len(words), chunk_size):
            chunk = " ".join(words[i:i + chunk_size])
            if len(chunk.strip()) > 30: #HERE ITS 100
                try:
                      summary = self.summarizer(f"summarize: {chunk}", max_length=80, min_length=30, do_sample=False)
                      summarized_chunks.append(summary[0]['generated_text'])
                except Exception:
                    continue
        return " ".join(summarized_chunks)

    def get_dynamic_headings(self, text):
        # 1. Pattern A: ALL CAPS (Major Chapters)
        major_h = re.findall(r'\n([A-Z\s\.]{6,45})\n', text)

        # 2. NEW Pattern B: Safe Roman Numerals [cite: 53, 54]
        # Must be at start of line, Roman Num, then 1-3 Capitalized words, then END of line
        roman_h = re.findall(r'\n([IVXLCDM]+\.?\s+[A-Z][a-z]+(?:\s[A-Z][a-z]+){0,2})\n', text)

        # 3. Pattern C: Title Case (Minor Sections like Seamounts, Atoll) [cite: 54]
        minor_h = re.findall(r'\n([A-Z][a-z]+(?:\s[A-Z][a-z]+){0,3})\n', text)

        # Combine and clean [cite: 56]
        all_candidates = [h.strip() for h in (major_h + roman_h + minor_h)]

        # 4. Dynamic Filters [cite: 58, 67, 69]
        noise_words = ["CHAPTER", "REPRINT", "PAGE", "UNIT"]
        clean = []
        for h in all_candidates:
            if not h.isdigit() and not any(noise in h.upper() for noise in noise_words):
                # Frequency Filter: Kills "Fundamentals" appearing on every page [cite: 69]
                if all_candidates.count(h) <= 2:
                    clean.append(h)

        # Filter for meaningful length (Kills 'iii', 'SH', 'SA')
        final_headings = [h for h in clean if len(h) > 3]

        # Return unique headers in order
        return list(dict.fromkeys(final_headings))

    def process_pdf(self, pdf_path):
        self.final_output = ""
        pages = convert_from_path(pdf_path)
        full_text = ""
        for page_img in pages:
            full_text += f"\n{pytesseract.image_to_string(page_img)}\n"

        self.headings = self.get_dynamic_headings(full_text)
        print(f"‚úÖ Found {len(self.headings)} Headings")

        # --- THE SEQUENTIAL ENGINE (The "Finger" Logic) ---
        last_pos = 0
        for i, curr_h in enumerate(self.headings):
            # 1. Find the START of this heading ONLY AFTER where we last stopped
            start_idx = full_text.find(curr_h, last_pos)
            if start_idx == -1: continue # Safety: skip if heading disappeared

            start = start_idx + len(curr_h)

            # 2. Find the END (The start of the NEXT heading in the list)
            if i + 1 < len(self.headings):
                # Search for the next heading ONLY AFTER the current one starts
                end = full_text.find(self.headings[i+1], start)
                if end == -1: end = len(full_text)
            else:
                end = len(full_text)

            # 3. CRUCIAL: Move the "Finger" forward to the start of this section
            # This ensures the NEXT search can't look back at old lists/noise.
            last_pos = start_idx

            # 4. Extract content and check the "Gatekeeper"
            content = self.clean_text(full_text[start:end])

            # Only summarize if it's a real paragraph (> 25 words)
            if len(content.split()) > 25:
                print(f"‚úçÔ∏è Summarizing: {curr_h}")
                summary = self.summarize_block(content)
                self.final_output += f"### {curr_h}\n{summary}\n\n"
            else:
                # If it's a "List Hit" (tiny content), merge it without a header
                self.final_output += f" {content} "

        return self.final_output

architect = HandwrittenNoteArchitect()

# Change this to your uploaded file name!
PDF_FILE_PATH = "/content/ocean.pdf"

if os.path.exists(PDF_FILE_PATH):
    final_notes = architect.process_pdf(PDF_FILE_PATH)

    # Save as a readable text file
    with open("handwritten_ready_notes.txt", "w") as f:
        f.write(final_notes)

    print("\n‚úÖ SUCCESS! Notes saved in 'handwritten_ready_notes.txt'")
    print("-" * 30)
    print(final_notes[:1000]) # Preview the first 1000 characters
else:
    print(f"‚ùå Error: Please upload '{PDF_FILE_PATH}' to the /content/ folder.")

from collections import Counter

# 1. Check if headings exist
if not architect.headings:
    print("‚ùå No headings found. Did you run architect.process_pdf() yet?")
else:
    # 2. Count occurrences of each heading
    counts = Counter(architect.headings)

    # 3. Identify duplicates
    duplicates = [item for item, count in counts.items() if count > 1]

    print("--- üìä ARCHITECT HEADING AUDIT ---")
    print(f"‚úÖ Total Headings Found: {len(architect.headings)}")
    print(f"üîÑ Duplicates Detected: {duplicates if duplicates else 'None'}")
    print("\nüìú FULL HEADING SEQUENCE (In Order):")

    # 4. Print with index to see exactly where they appear
    for idx, heading in enumerate(architect.headings):
        status = " [REPEAT]" if heading in duplicates else ""
        print(f"{idx}: {heading}{status}")

    # 5. Logical Check for the "List Trap"
    if "Deep Sea Plain" in duplicates:
        print("\nüí° INSIGHT: 'Deep Sea Plain' is duplicated. Sequential logic will skip the first hit (the list) and summarize the second hit (the actual content).")

from IPython.display import Markdown, display
display(Markdown(final_notes))

# 1. Download a "Messier" but clean font
!curl -L -o handwriting.ttf "https://github.com/google/fonts/raw/main/ofl/shadowsintolight/ShadowsIntoLight.ttf"

# 2. Check if it's valid
import os
print(f"Font size: {os.path.getsize('handwriting.ttf')} bytes")

!pip install fpdf2 -q

from fpdf import FPDF, XPos, YPos

class HandwrittenNoteRenderer(FPDF):
    def header(self):
        # Notebook appearance: Light blue horizontal lines
        self.set_draw_color(210, 235, 255)
        for i in range(25, 290, 8): # 8mm spacing for 'college ruled' look
            self.line(0, i, 210, i)

        # Red vertical margin line
        self.set_draw_color(255, 180, 180)
        self.line(30, 0, 30, 297)

        self.set_font('helvetica', 'I', 8)
        self.set_text_color(180)
        self.cell(0, 10, f'Notes | Page {self.page_no()}', new_x=XPos.RIGHT, new_y=YPos.TOP, align='R')
        self.ln(15)

    def write_notes(self, text):
        # Ink color: Navy Blue
        self.set_text_color(20, 40, 110)

        try:
            self.add_font('Handwritten', '', 'handwriting.ttf')
            self.set_font('Handwritten', '', 18)
        except Exception as e:
            print(f"‚ö†Ô∏è Font loading failed: {e}. Falling back to Helvetica.")
            self.set_font('helvetica', '', 12)

        self.set_auto_page_break(auto=True, margin=20)
        self.set_left_margin(35) # Stay right of the red line

        for line in text.split('\n'):
            if not line.strip():
                self.ln(8)
                continue

            if line.startswith('###'):
                # Headers look like a student used a thicker pen
                current_size = self.font_size_pt
                self.set_font(self.font_family, '', current_size + 4)
                self.multi_cell(0, 10, line.replace('###', '').strip())
                self.set_font(self.font_family, '', current_size)
            else:
                self.multi_cell(0, 8, line)
            self.ln(2)

# --- EXECUTION ---
pdf = HandwrittenNoteRenderer()
pdf.add_page()

# Pulling the content from your successful Architect process
if 'architect' in globals() and architect.final_output:
    pdf.write_notes(architect.final_output)
    pdf.output("Professional_Handwritten_Notes.pdf")
    print("üöÄ DONE! Download 'Professional_Handwritten_Notes.pdf' from the file sidebar.")
else:
    print("‚ùå No text found. Make sure you ran the architect.process_pdf() step!")
